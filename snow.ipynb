{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import pandas as pd\n",
    "import requests\n",
    "import re\n",
    "import numpy as np\n",
    "from time import sleep\n",
    "\n",
    "def read_all_sheets(fname='input/locations.xlsx'):\n",
    "    all_data = pd.read_excel(fname, sheet_name=None)\n",
    "    for continent in all_data:\n",
    "        all_data[continent]['continent'] = continent\n",
    "    return pd.concat(all_data.values())\n",
    "\n",
    "\n",
    "def parse_page(url: str):\n",
    "    snowpack = {}\n",
    "    measurement_date = {}\n",
    "\n",
    "    page = requests.get(url)\n",
    "    lines = (l.decode(\"utf-8\") for l in page.iter_lines())\n",
    "    snowfalls_pattern = re.compile('jssnowfalls([0-9]+)\\s*=\\s*(\\[.*\\])')\n",
    "    dates_pattern = re.compile('jsdates([0-9]+)\\s*=\\s*(\\[.*\\])')\n",
    "    \n",
    "    for line in lines:\n",
    "        snowfalls_match = snowfalls_pattern.findall(line)\n",
    "        dates_match = dates_pattern.findall(line)\n",
    "        if snowfalls_match:\n",
    "            assert len(snowfalls_match)==1\n",
    "            text_match = snowfalls_match[0]\n",
    "            year = int(text_match[0])\n",
    "            data = json.loads(text_match[1])\n",
    "            snowpack[year] = data\n",
    "        if dates_match:\n",
    "            assert len(dates_match)==1\n",
    "            text_match = dates_match[0]\n",
    "            year = int(text_match[0])\n",
    "            data = json.loads(text_match[1])\n",
    "            measurement_date[year] = data\n",
    "    return snowpack, measurement_date\n",
    "    \n",
    "\n",
    "def dicts_to_df(snow_data, dates, data_type):\n",
    "    yearly_dfs = []\n",
    "    for year in snow_data.keys():\n",
    "        df = pd.DataFrame(zip(snow_data[year], dates[year]),\n",
    "                          columns=[data_type, 'date'])\n",
    "        df['season'] = year\n",
    "        yearly_dfs.append(df)\n",
    "    out = pd.concat(yearly_dfs)\n",
    "    return out\n",
    "\n",
    "def get_one_resort(continent: str, region: str, resort: str):\n",
    "    \n",
    "    resort_base_url = \"/\".join([\"https://www.onthesnow.com\", region, resort, \"historical-snowfall.html?y=0\"]) # y=0 gets multiple years in one call\n",
    "    snowpack_url = resort_base_url + \"&q=top\"\n",
    "    snowfall_url = resort_base_url + \"&q=snow\"    \n",
    "    snowpack, snowpack_dates = parse_page(snowpack_url)\n",
    "    snowpack_df = dicts_to_df(snowpack, snowpack_dates, \"snowpack\")\n",
    "    snowpack_df = snowpack_df[snowpack_df.snowpack>0]\n",
    "    snowpack_df = snowpack_df[snowpack_df.snowpack<400]\n",
    "    snowfall, snowfall_dates = parse_page(snowfall_url)\n",
    "    snowfall_df = dicts_to_df(snowfall, snowfall_dates, \"snowfall\")\n",
    "    for df in (snowpack_df, snowfall_df):\n",
    "        df['continent'] = continent\n",
    "        df['region'] = region\n",
    "        df['resort'] = resort\n",
    "        df['date'] = pd.to_datetime(df.date)\n",
    "        df['day_of_year'] = df.date.dt.dayofyear\n",
    "    return {'snowpack': snowpack_df, 'snowfall': snowfall_df}\n",
    "\n",
    "def stochastic_sleep(min, max):\n",
    "    sleep(np.random.uniform(min, max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on bjoerkliden\n",
      "Error on meribe\n",
      "Error on riksgransen\n",
      "Error on crystal-mountain-wa\n",
      "Error on silverton-mountain\n"
     ]
    }
   ],
   "source": [
    "snow_data_accumulator = []\n",
    "\n",
    "locations = read_all_sheets()\n",
    "\n",
    "for index, row_data in locations.iterrows():\n",
    "    # one source of erorrs is getting the resort name wrong do to character encoding stuff\n",
    "    try:\n",
    "        snow_data_accumulator.append(get_one_resort(row_data.continent, row_data.Region, row_data.Resort))\n",
    "    except:\n",
    "        print(f\"Error on {row_data.Resort}\")\n",
    "    stochastic_sleep(1, 2)\n",
    "\n",
    "snowpack = pd.concat(resort_data['snowpack'] for resort_data in snow_data_accumulator)\n",
    "snowfall = pd.concat(resort_data['snowfall'] for resort_data in snow_data_accumulator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "snowpack.to_csv('output/snowpack.csv', index=False)\n",
    "snowfall.to_csv('output/snowfall.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "snowpack = pd.read_csv('output/snowpack.csv', parse_dates=['date'])\n",
    "snowfall = pd.read_csv('output/snowfall.csv', parse_dates=['date'])\n",
    "\n",
    "snowpack['dayofyear'] = snowpack.date.dt.dayofyear\n",
    "snowfall['dayofyear'] = snowfall.date.dt.dayofyear\n",
    "\n",
    "DAY_TO_TRACK = 92\n",
    "usable_seasons = snowpack.query('season > 2011 and season < 2019')\n",
    "# Some resorts don't report every day... so take the first one after ...\n",
    "days_after_threshold = usable_seasons[usable_seasons.date.dt.dayofyear>DAY_TO_TRACK]\n",
    "to_plot = days_after_threshold.loc[days_after_threshold.groupby([\"resort\", \"season\"])[\"dayofyear\"].idxmin()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "import altair as alt\n",
    "\n",
    "for resort in to_plot.resort.unique():\n",
    "    current_resort_data = to_plot[to_plot.resort == resort]\n",
    "    snowpack_chart = alt.Chart(current_resort_data, title=resort).mark_point().encode(\n",
    "        alt.X('season:N'),\n",
    "        alt.Y('snowpack', title='Snowpack on April 1')\n",
    "    ).properties(width=600)\n",
    "    \n",
    "#     display(snowpack_chart + snowpack_chart.transform_regression('season', 'snowpack').mark_line())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/statsmodels/compat/pandas.py:49: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  data_klasses = (pandas.Series, pandas.DataFrame, pandas.Panel)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>snowpack</td>     <th>  R-squared:         </th> <td>   0.000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>  -0.000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>  0.3289</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 05 Dec 2020</td> <th>  Prob (F-statistic):</th>  <td> 0.566</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>19:27:32</td>     <th>  Log-Likelihood:    </th> <td> -20386.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  3932</td>      <th>  AIC:               </th> <td>4.078e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  3930</td>      <th>  BIC:               </th> <td>4.079e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "     <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>  <td> -343.0023</td> <td>  690.437</td> <td>   -0.497</td> <td> 0.619</td> <td>-1696.651</td> <td> 1010.646</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>season</th> <td>    0.1965</td> <td>    0.343</td> <td>    0.574</td> <td> 0.566</td> <td>   -0.475</td> <td>    0.868</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>1125.144</td> <th>  Durbin-Watson:     </th> <td>   0.903</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>2966.936</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 1.536</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td> 5.945</td>  <th>  Cond. No.          </th> <td>2.02e+06</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 2.02e+06. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:               snowpack   R-squared:                       0.000\n",
       "Model:                            OLS   Adj. R-squared:                 -0.000\n",
       "Method:                 Least Squares   F-statistic:                    0.3289\n",
       "Date:                Sat, 05 Dec 2020   Prob (F-statistic):              0.566\n",
       "Time:                        19:27:32   Log-Likelihood:                -20386.\n",
       "No. Observations:                3932   AIC:                         4.078e+04\n",
       "Df Residuals:                    3930   BIC:                         4.079e+04\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       -343.0023    690.437     -0.497      0.619   -1696.651    1010.646\n",
       "season         0.1965      0.343      0.574      0.566      -0.475       0.868\n",
       "==============================================================================\n",
       "Omnibus:                     1125.144   Durbin-Watson:                   0.903\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2966.936\n",
       "Skew:                           1.536   Prob(JB):                         0.00\n",
       "Kurtosis:                       5.945   Cond. No.                     2.02e+06\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 2.02e+06. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "exog = sm.add_constant(to_plot.season)\n",
    "model = smf.OLS(endog=to_plot.snowpack, exog = exog, data=to_plot).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>continent</th>\n",
       "      <th>season</th>\n",
       "      <th>snowfall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Europe</td>\n",
       "      <td>2012</td>\n",
       "      <td>27585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Europe</td>\n",
       "      <td>2013</td>\n",
       "      <td>25851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Europe</td>\n",
       "      <td>2014</td>\n",
       "      <td>23935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Europe</td>\n",
       "      <td>2015</td>\n",
       "      <td>22796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Europe</td>\n",
       "      <td>2016</td>\n",
       "      <td>18907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Europe</td>\n",
       "      <td>2017</td>\n",
       "      <td>34713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Europe</td>\n",
       "      <td>2018</td>\n",
       "      <td>29860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>North America</td>\n",
       "      <td>2012</td>\n",
       "      <td>43636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>North America</td>\n",
       "      <td>2013</td>\n",
       "      <td>48061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>North America</td>\n",
       "      <td>2014</td>\n",
       "      <td>33581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>North America</td>\n",
       "      <td>2015</td>\n",
       "      <td>42848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>North America</td>\n",
       "      <td>2016</td>\n",
       "      <td>57476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>North America</td>\n",
       "      <td>2017</td>\n",
       "      <td>45203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>North America</td>\n",
       "      <td>2018</td>\n",
       "      <td>49072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>South America</td>\n",
       "      <td>2012</td>\n",
       "      <td>243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>South America</td>\n",
       "      <td>2013</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>South America</td>\n",
       "      <td>2014</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>South America</td>\n",
       "      <td>2015</td>\n",
       "      <td>375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>South America</td>\n",
       "      <td>2016</td>\n",
       "      <td>333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>South America</td>\n",
       "      <td>2017</td>\n",
       "      <td>287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>South America</td>\n",
       "      <td>2018</td>\n",
       "      <td>386</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        continent  season  snowfall\n",
       "0          Europe    2012     27585\n",
       "1          Europe    2013     25851\n",
       "2          Europe    2014     23935\n",
       "3          Europe    2015     22796\n",
       "4          Europe    2016     18907\n",
       "5          Europe    2017     34713\n",
       "6          Europe    2018     29860\n",
       "7   North America    2012     43636\n",
       "8   North America    2013     48061\n",
       "9   North America    2014     33581\n",
       "10  North America    2015     42848\n",
       "11  North America    2016     57476\n",
       "12  North America    2017     45203\n",
       "13  North America    2018     49072\n",
       "14  South America    2012       243\n",
       "15  South America    2013       136\n",
       "16  South America    2014       172\n",
       "17  South America    2015       375\n",
       "18  South America    2016       333\n",
       "19  South America    2017       287\n",
       "20  South America    2018       386"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_snowfall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "continent      season\n",
       "Europe         2012      214\n",
       "               2013      216\n",
       "               2014      217\n",
       "               2015      217\n",
       "               2016      217\n",
       "               2017      217\n",
       "               2018      217\n",
       "North America  2012      357\n",
       "               2013      361\n",
       "               2014      362\n",
       "               2015      362\n",
       "               2016      361\n",
       "               2017      360\n",
       "               2018      361\n",
       "South America  2012       11\n",
       "               2013       11\n",
       "               2014       11\n",
       "               2015       10\n",
       "               2016       11\n",
       "               2017       11\n",
       "               2018       11\n",
       "Name: resort, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snowfall.query('season > 2011 and season < 2019').groupby(['continent', 'season']).resort.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-594\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  (function(spec, embedOpt){\n",
       "    const outputDiv = document.getElementById(\"altair-viz-594\");\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.0.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function loadScript(lib) {\n",
       "      return new Promise(function(resolve, reject) {\n",
       "        var s = document.createElement('script');\n",
       "        s.src = paths[lib];\n",
       "        s.async = true;\n",
       "        s.onload = () => resolve(paths[lib]);\n",
       "        s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "        document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "      });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else if (typeof vegaEmbed === \"function\") {\n",
       "      displayChart(vegaEmbed);\n",
       "    } else {\n",
       "      loadScript(\"vega\")\n",
       "        .then(() => loadScript(\"vega-lite\"))\n",
       "        .then(() => loadScript(\"vega-embed\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-0eff0541894e5b32452d6bb863dba455\"}, \"mark\": \"point\", \"encoding\": {\"color\": {\"type\": \"nominal\", \"field\": \"continent\"}, \"x\": {\"type\": \"nominal\", \"field\": \"season\"}, \"y\": {\"type\": \"quantitative\", \"field\": \"snowfall\"}}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.0.0.json\", \"datasets\": {\"data-0eff0541894e5b32452d6bb863dba455\": [{\"continent\": \"Europe\", \"season\": 2012, \"snowfall\": 27585}, {\"continent\": \"Europe\", \"season\": 2013, \"snowfall\": 25851}, {\"continent\": \"Europe\", \"season\": 2014, \"snowfall\": 23935}, {\"continent\": \"Europe\", \"season\": 2015, \"snowfall\": 22796}, {\"continent\": \"Europe\", \"season\": 2016, \"snowfall\": 18907}, {\"continent\": \"Europe\", \"season\": 2017, \"snowfall\": 34713}, {\"continent\": \"Europe\", \"season\": 2018, \"snowfall\": 29860}, {\"continent\": \"North America\", \"season\": 2012, \"snowfall\": 43636}, {\"continent\": \"North America\", \"season\": 2013, \"snowfall\": 48061}, {\"continent\": \"North America\", \"season\": 2014, \"snowfall\": 33581}, {\"continent\": \"North America\", \"season\": 2015, \"snowfall\": 42848}, {\"continent\": \"North America\", \"season\": 2016, \"snowfall\": 57476}, {\"continent\": \"North America\", \"season\": 2017, \"snowfall\": 45203}, {\"continent\": \"North America\", \"season\": 2018, \"snowfall\": 49072}, {\"continent\": \"South America\", \"season\": 2012, \"snowfall\": 243}, {\"continent\": \"South America\", \"season\": 2013, \"snowfall\": 136}, {\"continent\": \"South America\", \"season\": 2014, \"snowfall\": 172}, {\"continent\": \"South America\", \"season\": 2015, \"snowfall\": 375}, {\"continent\": \"South America\", \"season\": 2016, \"snowfall\": 333}, {\"continent\": \"South America\", \"season\": 2017, \"snowfall\": 287}, {\"continent\": \"South America\", \"season\": 2018, \"snowfall\": 386}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_snowfall = snowfall.query('season > 2011 and season < 2019').groupby(['continent', 'season']).snowfall.sum().reset_index()\n",
    "\n",
    "alt.Chart(total_snowfall).mark_point().encode(\n",
    "    alt.X('season:N'),\n",
    "    alt.Y('snowfall'),\n",
    "    alt.Color('continent')\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
